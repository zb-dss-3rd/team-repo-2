{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydicom.pixel_data_handlers.util import apply_modality_lut, apply_voi_lut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 파이퍼 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_IMAGES_3D = 64\n",
    "TRAINING_BATCH_SIZE = 4\n",
    "TEST_BATCH_SIZE = 4\n",
    "IMAGE_SIZE = 256\n",
    "N_EPOCHS = 10\n",
    "do_valid = True\n",
    "n_workers = 0\n",
    "type_ = \"T1wCE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load dicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom_image(path, img_size=IMAGE_SIZE, voi_lut=True, rotate=0):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    data = dicom.pixel_array\n",
    "    \n",
    "    # voi_lut\n",
    "    if voi_lut:\n",
    "        data = apply_voi_lut(dicom.pixel_array, dicom)\n",
    "    else:\n",
    "        data = dicom.pixel_array\n",
    "\n",
    "    # 회전 옵션\n",
    "    if rotate > 0:\n",
    "        rot_choices = [\n",
    "            0,\n",
    "            cv2.ROTATE_90_CLOCKWISE,\n",
    "            cv2.ROTATE_90_COUNTERCLOCKWISE,\n",
    "            cv2.ROTATE_180,\n",
    "        ]\n",
    "        data = cv2.rotate(data, rot_choices[rotate])\n",
    "\n",
    "    data = cv2.resize(data, (img_size, img_size))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BrainRSNADataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrainRSNADataset(Dataset):\n",
    "    def __init__(\n",
    "        self, data, transform=None, target=\"MGMT_value\", mri_type=\"FLAIR\", is_train=True\n",
    "    ):\n",
    "        self.target = target\n",
    "        self.data = data\n",
    "        self.type = mri_type\n",
    "\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.folder = \"train\" if self.is_train else \"test\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.data.loc[index]\n",
    "        case_id = int(row.BraTS21ID)\n",
    "        target = int(row[self.target])\n",
    "        _3d_images = self.load_dicom_images_3d(case_id)\n",
    "        _3d_images = torch.tensor(_3d_images).float()\n",
    "        if self.is_train:\n",
    "            return {\"image\": _3d_images, \"target\": target}\n",
    "        else:\n",
    "            return {\"image\": _3d_images, \"case_id\": case_id}\n",
    "\n",
    "    def load_dicom_images_3d(\n",
    "        self,\n",
    "        case_id,\n",
    "        num_imgs=NUM_IMAGES_3D,\n",
    "        img_size=IMAGE_SIZE,\n",
    "        rotate=0,\n",
    "    ):\n",
    "        case_id = str(case_id).zfill(5)\n",
    "\n",
    "        path = f\"./data/{self.folder}/{case_id}/{self.type}/*.dcm\"\n",
    "        files = sorted(\n",
    "            glob.glob(path),\n",
    "            key=lambda var: [\n",
    "                int(x) if x.isdigit() else x for x in re.findall(r\"[^0-9]|[0-9]+\", var)\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        middle = len(files) // 2\n",
    "        num_imgs2 = num_imgs // 2\n",
    "        p1 = max(0, middle - num_imgs2)\n",
    "        p2 = min(len(files), middle + num_imgs2)\n",
    "        image_stack = [load_dicom_image(f, rotate=rotate) for f in files[p1:p2]]\n",
    "        \n",
    "        img3d = np.stack(image_stack).T\n",
    "        if img3d.shape[-1] < num_imgs:\n",
    "            n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n",
    "            img3d = np.concatenate((img3d, n_zero), axis=-1)\n",
    "\n",
    "        if np.min(img3d) < np.max(img3d):\n",
    "            img3d = img3d - np.min(img3d)\n",
    "            img3d = img3d / np.max(img3d)\n",
    "\n",
    "        return np.expand_dims(img3d, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "\n",
    "# model \n",
    "model = monai.networks.nets.resnet10(spatial_dims=3, n_input_channels=1, n_classes=1)\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device);\n",
    "all_weights = os.listdir(\"./data/resnet10-rsna\")\n",
    "fold_files = [f for f in all_weights if type_ in f]\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3d-resnet10_T1wCE_fold0_0.565.pth',\n",
       " '3d-resnet10_T1wCE_fold1_0.573.pth',\n",
       " '3d-resnet10_T1wCE_fold2_0.538.pth',\n",
       " '3d-resnet10_T1wCE_fold3_0.664.pth',\n",
       " '3d-resnet10_T1wCE_fold4_0.551.pth']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"./data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:39<00:00,  1.78s/it]\n",
      "100%|██████████| 22/22 [00:15<00:00,  1.43it/s]\n",
      "100%|██████████| 22/22 [00:15<00:00,  1.46it/s]\n",
      "100%|██████████| 22/22 [00:18<00:00,  1.19it/s]\n",
      "100%|██████████| 22/22 [00:15<00:00,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "tta_true_labels = []\n",
    "tta_preds = []\n",
    "test_dataset = BrainRSNADataset(data=sample, mri_type=type_, is_train=False)\n",
    "test_dl = torch.utils.data.DataLoader(\n",
    "        test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=n_workers\n",
    "    )\n",
    "\n",
    "preds_f = np.zeros(len(sample))\n",
    "for fold in range(5):\n",
    "    image_ids = []\n",
    "    model.load_state_dict(torch.load(f\"./data/resnet10-rsna/{fold_files[fold]}\"))\n",
    "    preds = []\n",
    "    epoch_iterator_test = tqdm(test_dl)\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(epoch_iterator_test):\n",
    "            model.eval()\n",
    "            images = batch[\"image\"].to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            preds.append(outputs.sigmoid().detach().cpu().numpy())\n",
    "            image_ids.append(batch[\"case_id\"].detach().cpu().numpy())\n",
    "    \n",
    "\n",
    "    preds_f += np.vstack(preds).T[0]/5\n",
    "\n",
    "    ids_f = np.hstack(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample[\"BraTS21ID\"] = ids_f\n",
    "sample[\"MGMT_value\"] = preds_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample.sort_values(by=\"BraTS21ID\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BraTS21ID</th>\n",
       "      <th>MGMT_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.543852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0.551282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.558330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>0.552038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>0.546800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>826</td>\n",
       "      <td>0.457712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>829</td>\n",
       "      <td>0.430619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>833</td>\n",
       "      <td>0.502583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>997</td>\n",
       "      <td>0.525578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1006</td>\n",
       "      <td>0.540014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    BraTS21ID  MGMT_value\n",
       "0           1    0.543852\n",
       "1          13    0.551282\n",
       "2          15    0.558330\n",
       "3          27    0.552038\n",
       "4          37    0.546800\n",
       "..        ...         ...\n",
       "82        826    0.457712\n",
       "83        829    0.430619\n",
       "84        833    0.502583\n",
       "85        997    0.525578\n",
       "86       1006    0.540014\n",
       "\n",
       "[87 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('jtk')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0edc4ebc751df66f2f329166b5209891afa3e4f58d7cb42ab5ccb6b0e6ddf96c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
