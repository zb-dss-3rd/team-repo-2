{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d1d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut,apply_modality_lut\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3c02a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (512, 512)\n",
    "IMAGE_TYPE = 'T1wCE'\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "IMAGE_SAMP_DIV = 5\n",
    "KERNEL_SIZE = (3,3)\n",
    "\n",
    "EPOCHS = 50\n",
    "\n",
    "WEIGHT_FILE = '_05_best-model-efficientnet_b0_t1wce_512_gradient.pth'\n",
    "base_path = 'D:/zerobase/Brain_tumor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3559c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom(path):\n",
    "    \n",
    "    dicom = pydicom.read_file(path)\n",
    "    data = dicom.pixel_array\n",
    "    \n",
    "#     data = apply_modality_lut(data, dicom)   # modality 적용\n",
    "#     data = apply_voi_lut(data,dicom)         # voi 적용\n",
    "    \n",
    "    data = data - np.min(data)\n",
    "    if np.max(data) != 0:\n",
    "        data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    \n",
    "    k = cv2.getStructuringElement(cv2.MORPH_RECT,KERNEL_SIZE)  # tophat or gradient 적용시 활성화\n",
    "#     data = cv2.morphologyEx(data, cv2.MORPH_TOPHAT, k)       # tophat 적용\n",
    "    data = cv2.morphologyEx(data, cv2.MORPH_GRADIENT, k)       # gradient 적용\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54ef0002",
   "metadata": {},
   "outputs": [],
   "source": [
    "package_path = base_path + \"/efficientnet/EfficientNet-PyTorch/EfficientNet-PyTorch-master/\"\n",
    "import sys \n",
    "sys.path.append(package_path)\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data as torch_data\n",
    "from sklearn import model_selection as sk_model_selection\n",
    "from torch.nn import functional as torch_functional\n",
    "import efficientnet_pytorch\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "661f0b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a43f1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(base_path + \"/train_df.csv\")\n",
    "df_train, df_valid = sk_model_selection.train_test_split(\n",
    "    df, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=df[\"MGMT_value\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6085640",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataRetriever(torch_data.Dataset):\n",
    "    def __init__(self, paths, targets):\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "          \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        _id = self.paths[index]\n",
    "        patient_path = base_path + f\"/train/{str(_id).zfill(5)}/\"\n",
    "        channels = []\n",
    "#         for t in (\"FLAIR\", \"T1w\", \"T1wCE\"): # \"T2w\"\n",
    "        for t in (IMAGE_TYPE,IMAGE_TYPE,IMAGE_TYPE): # \"FLAIR\", \"T1w\", \"T2w\"\n",
    "            t_paths = sorted(\n",
    "                glob.glob(os.path.join(patient_path, t, \"*\")), \n",
    "                key=lambda x: int(x[:-4].split(\"-\")[-1]),\n",
    "            )\n",
    "            x = len(t_paths)\n",
    "            if x < IMAGE_SAMP_DIV:\n",
    "                r = range(x)\n",
    "            else:\n",
    "                d = x // IMAGE_SAMP_DIV\n",
    "                r = range(d, x - d, d)\n",
    "                \n",
    "            channel = []\n",
    "            # for i in range(start, end + 1):\n",
    "            for i in r:\n",
    "                channel.append(cv2.resize(load_dicom(t_paths[i]), IMAGE_SIZE) / 255)\n",
    "            channel = np.mean(channel, axis=0)\n",
    "            channels.append(channel)\n",
    "            \n",
    "        y = torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        \n",
    "        return {\"X\": torch.tensor(channels).float(), \"y\": y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7ef4bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_retriever = DataRetriever(\n",
    "    df_train[\"BraTS21ID\"].values, \n",
    "    df_train[\"MGMT_value\"].values, \n",
    ")\n",
    "\n",
    "valid_data_retriever = DataRetriever(\n",
    "    df_valid[\"BraTS21ID\"].values, \n",
    "    df_valid[\"MGMT_value\"].values,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc21056b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = efficientnet_pytorch.EfficientNet.from_name(\"efficientnet-b0\")\n",
    "        checkpoint = torch.load(base_path + \"/efficientnet/efficientnet-b0-08094119.pth\")\n",
    "        self.net.load_state_dict(checkpoint)\n",
    "        n_features = self.net._fc.in_features\n",
    "        print('n_features : ', n_features)\n",
    "        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adc22545",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossMeter:\n",
    "    def __init__(self):\n",
    "        self.avg = 0\n",
    "        self.n = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        self.n += 1\n",
    "        # incremental update\n",
    "        self.avg = val / self.n + (self.n - 1) / self.n * self.avg\n",
    "\n",
    "        \n",
    "class AccMeter:\n",
    "    def __init__(self):\n",
    "        self.avg = 0\n",
    "        self.n = 0\n",
    "        \n",
    "    def update(self, y_true, y_pred):\n",
    "        y_true = y_true.cpu().numpy().astype(int)\n",
    "        y_pred = y_pred.cpu().numpy() >= 0\n",
    "        last_n = self.n\n",
    "        self.n += len(y_true)\n",
    "        true_count = np.sum(y_true == y_pred)\n",
    "        # incremental update\n",
    "        self.avg = true_count / self.n + last_n / self.n * self.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d15e72d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model, \n",
    "        device, \n",
    "        optimizer, \n",
    "        criterion, \n",
    "        loss_meter, \n",
    "        score_meter\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.loss_meter = loss_meter\n",
    "        self.score_meter = score_meter\n",
    "        \n",
    "        self.best_valid_score = -np.inf\n",
    "        self.n_patience = 0\n",
    "        \n",
    "        self.messages = {\n",
    "            \"epoch\": \"[Epoch {}: {}] loss: {:.5f}, score: {:.5f}, time: {} s\",\n",
    "            \"checkpoint\": \"The score improved from {:.5f} to {:.5f}. Save model to '{}'\",\n",
    "            \"patience\": \"\\nValid score didn't improve last {} epochs.\"\n",
    "        }\n",
    "    \n",
    "    def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n",
    "        for n_epoch in range(1, epochs + 1):\n",
    "            self.info_message(\"EPOCH: {}\", n_epoch)\n",
    "            \n",
    "            train_loss, train_score, train_time = self.train_epoch(train_loader)\n",
    "            valid_loss, valid_score, valid_time = self.valid_epoch(valid_loader)\n",
    "            \n",
    "            self.info_message(\n",
    "                self.messages[\"epoch\"], \"Train\", n_epoch, train_loss, train_score, train_time\n",
    "            )\n",
    "            \n",
    "            self.info_message(\n",
    "                self.messages[\"epoch\"], \"Valid\", n_epoch, valid_loss, valid_score, valid_time\n",
    "            )\n",
    "\n",
    "            if True:\n",
    "                if self.best_valid_score < valid_score :\n",
    "                    self.info_message(\n",
    "                        self.messages[\"checkpoint\"], self.best_valid_score, valid_score, save_path\n",
    "                    )\n",
    "                    self.best_valid_score = valid_score\n",
    "                    self.save_model(n_epoch, save_path)\n",
    "                    self.n_patience = 0\n",
    "                else:\n",
    "                    self.n_patience += 1\n",
    "            \n",
    "            if self.n_patience >= patience:\n",
    "                self.info_message(self.messages[\"patience\"], patience)\n",
    "                break\n",
    "            \n",
    "    def train_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        t = time.time()\n",
    "        train_loss = self.loss_meter()\n",
    "        train_score = self.score_meter()\n",
    "        \n",
    "        for step, batch in enumerate(train_loader, 1):\n",
    "            X = batch[\"X\"].to(self.device)\n",
    "            targets = batch[\"y\"].to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(X).squeeze(1)\n",
    "            \n",
    "            loss = self.criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            train_loss.update(loss.detach().item())\n",
    "            train_score.update(targets, outputs.detach())\n",
    "\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            _loss, _score = train_loss.avg, train_score.avg\n",
    "            message = 'Train Step {}/{}, train_loss: {:.5f}, train_score: {:.5f}'\n",
    "            self.info_message(message, step, len(train_loader), _loss, _score, end=\"\\r\")\n",
    "        \n",
    "        return train_loss.avg, train_score.avg, int(time.time() - t)\n",
    "    \n",
    "    def valid_epoch(self, valid_loader):\n",
    "        self.model.eval()\n",
    "        t = time.time()\n",
    "        valid_loss = self.loss_meter()\n",
    "        valid_score = self.score_meter()\n",
    "\n",
    "        for step, batch in enumerate(valid_loader, 1):\n",
    "            with torch.no_grad():\n",
    "                X = batch[\"X\"].to(self.device)\n",
    "                targets = batch[\"y\"].to(self.device)\n",
    "\n",
    "                outputs = self.model(X).squeeze(1)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                valid_loss.update(loss.detach().item())\n",
    "                valid_score.update(targets, outputs)\n",
    "                \n",
    "            _loss, _score = valid_loss.avg, valid_score.avg\n",
    "            message = 'Valid Step {}/{}, valid_loss: {:.5f}, valid_score: {:.5f}'\n",
    "            self.info_message(message, step, len(valid_loader), _loss, _score, end=\"\\r\")\n",
    "        \n",
    "        return valid_loss.avg, valid_score.avg, int(time.time() - t)\n",
    "    \n",
    "    def save_model(self, n_epoch, save_path):\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": self.model.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"best_valid_score\": self.best_valid_score,\n",
    "                \"n_epoch\": n_epoch,\n",
    "            },\n",
    "            save_path,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def info_message(message, *args, end=\"\\n\"):\n",
    "        print(message.format(*args), end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e01368d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "n_features :  1280\n",
      "EPOCH: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\story\\AppData\\Local\\Temp/ipykernel_7568/1453552745.py:35: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:210.)\n",
      "  return {\"X\": torch.tensor(channels).float(), \"y\": y}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch Train: 1] loss: 0.72466, score: 0.51070, time: 100 s70\n",
      "[Epoch Valid: 1] loss: 0.69241, score: 0.52128, time: 21 s\n",
      "The score improved from -inf to 0.52128. Save model to '_05_best-model-efficientnet_b0_t1wce_512_gradient.pth'\n",
      "EPOCH: 2\n",
      "[Epoch Train: 2] loss: 0.71802, score: 0.48930, time: 84 s030\n",
      "[Epoch Valid: 2] loss: 0.74631, score: 0.50000, time: 17 s\n",
      "EPOCH: 3\n",
      "[Epoch Train: 3] loss: 0.71063, score: 0.48396, time: 70 s496\n",
      "[Epoch Valid: 3] loss: 0.68106, score: 0.59574, time: 11 s\n",
      "The score improved from 0.52128 to 0.59574. Save model to '_05_best-model-efficientnet_b0_t1wce_512_gradient.pth'\n",
      "EPOCH: 4\n",
      "[Epoch Train: 4] loss: 0.71030, score: 0.46257, time: 61 s457\n",
      "[Epoch Valid: 4] loss: 0.89043, score: 0.51064, time: 11 s\n",
      "EPOCH: 5\n",
      "[Epoch Train: 5] loss: 0.71370, score: 0.48128, time: 61 s028\n",
      "[Epoch Valid: 5] loss: 0.70165, score: 0.50000, time: 11 s\n",
      "EPOCH: 6\n",
      "[Epoch Train: 6] loss: 0.70676, score: 0.48128, time: 62 s728\n",
      "[Epoch Valid: 6] loss: 0.68507, score: 0.57447, time: 11 s\n",
      "EPOCH: 7\n",
      "[Epoch Train: 7] loss: 0.70511, score: 0.51337, time: 61 s837\n",
      "[Epoch Valid: 7] loss: 0.78616, score: 0.52128, time: 11 s\n",
      "EPOCH: 8\n",
      "[Epoch Train: 8] loss: 0.69722, score: 0.53209, time: 61 s209\n",
      "[Epoch Valid: 8] loss: 0.70088, score: 0.47872, time: 11 s\n",
      "EPOCH: 9\n",
      "[Epoch Train: 9] loss: 0.70127, score: 0.52674, time: 62 s974\n",
      "[Epoch Valid: 9] loss: 0.68679, score: 0.55319, time: 11 s\n",
      "EPOCH: 10\n",
      "[Epoch Train: 10] loss: 0.70355, score: 0.48663, time: 61 s63\n",
      "[Epoch Valid: 10] loss: 0.68717, score: 0.54255, time: 11 s\n",
      "EPOCH: 11\n",
      "[Epoch Train: 11] loss: 0.70337, score: 0.47594, time: 61 s94\n",
      "[Epoch Valid: 11] loss: 0.68301, score: 0.60638, time: 11 s\n",
      "The score improved from 0.59574 to 0.60638. Save model to '_05_best-model-efficientnet_b0_t1wce_512_gradient.pth'\n",
      "EPOCH: 12\n",
      "[Epoch Train: 12] loss: 0.69781, score: 0.51070, time: 61 s70\n",
      "[Epoch Valid: 12] loss: 0.69148, score: 0.52128, time: 11 s\n",
      "EPOCH: 13\n",
      "[Epoch Train: 13] loss: 0.69204, score: 0.53743, time: 61 s43\n",
      "[Epoch Valid: 13] loss: 0.77508, score: 0.47872, time: 11 s\n",
      "EPOCH: 14\n",
      "[Epoch Train: 14] loss: 0.70139, score: 0.51070, time: 61 s70\n",
      "[Epoch Valid: 14] loss: 0.90599, score: 0.54255, time: 11 s\n",
      "EPOCH: 15\n",
      "[Epoch Train: 15] loss: 0.70222, score: 0.48128, time: 61 s28\n",
      "[Epoch Valid: 15] loss: 0.71075, score: 0.47872, time: 11 s\n",
      "EPOCH: 16\n",
      "[Epoch Train: 16] loss: 0.69798, score: 0.54278, time: 61 s78\n",
      "[Epoch Valid: 16] loss: 2.45537, score: 0.52128, time: 11 s\n",
      "EPOCH: 17\n",
      "[Epoch Train: 17] loss: 0.70111, score: 0.52139, time: 61 s39\n",
      "[Epoch Valid: 17] loss: 0.87895, score: 0.50000, time: 11 s\n",
      "EPOCH: 18\n",
      "[Epoch Train: 18] loss: 0.69985, score: 0.54278, time: 61 s78\n",
      "[Epoch Valid: 18] loss: 0.69406, score: 0.52128, time: 11 s\n",
      "EPOCH: 19\n",
      "[Epoch Train: 19] loss: 0.70350, score: 0.49733, time: 64 s33\n",
      "[Epoch Valid: 19] loss: 0.68241, score: 0.54255, time: 12 s\n",
      "EPOCH: 20\n",
      "[Epoch Train: 20] loss: 0.69968, score: 0.51070, time: 65 s70\n",
      "[Epoch Valid: 20] loss: 0.70169, score: 0.48936, time: 18 s\n",
      "EPOCH: 21\n",
      "[Epoch Train: 21] loss: 0.69359, score: 0.52674, time: 79 s74\n",
      "[Epoch Valid: 21] loss: 0.70650, score: 0.59574, time: 14 s\n",
      "\n",
      "Valid score didn't improve last 10 epochs.\n",
      "Wall time: 27min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device=\"cpu\"\n",
    "print(device)\n",
    "\n",
    "train_data_retriever = DataRetriever(\n",
    "    df_train[\"BraTS21ID\"].values, \n",
    "    df_train[\"MGMT_value\"].values, \n",
    ")\n",
    "\n",
    "valid_data_retriever = DataRetriever(\n",
    "    df_valid[\"BraTS21ID\"].values, \n",
    "    df_valid[\"MGMT_value\"].values,\n",
    ")\n",
    "\n",
    "# train_loader = torch_data.DataLoader(\n",
    "#     train_data_retriever,\n",
    "#     batch_size=8,\n",
    "#     shuffle=True,\n",
    "#     num_workers=8,\n",
    "# )\n",
    "\n",
    "# valid_loader = torch_data.DataLoader(\n",
    "#     valid_data_retriever, \n",
    "#     batch_size=8,\n",
    "#     shuffle=False,\n",
    "#     num_workers=8,\n",
    "# )\n",
    "\n",
    "train_loader = torch_data.DataLoader(\n",
    "    train_data_retriever,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "valid_loader = torch_data.DataLoader(\n",
    "    valid_data_retriever, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "model = Model()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch_functional.binary_cross_entropy_with_logits\n",
    "\n",
    "trainer = Trainer(\n",
    "    model, \n",
    "    device, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    LossMeter, \n",
    "    AccMeter\n",
    ")\n",
    "\n",
    "history = trainer.fit(\n",
    "    EPOCHS, \n",
    "    train_loader, \n",
    "    valid_loader, \n",
    "    WEIGHT_FILE, \n",
    "    10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0acbf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features :  1280\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "# for i in range(1):\n",
    "#     model = Model()\n",
    "#     model.to(device)\n",
    "    \n",
    "#     checkpoint = torch.load(f\"best-model-{i}.pth\")\n",
    "#     model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "#     model.eval()\n",
    "    \n",
    "#     models.append(model)\n",
    "\n",
    "model = Model()\n",
    "model.to(device)\n",
    "    \n",
    "checkpoint = torch.load(WEIGHT_FILE)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a45f7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataRetriever(torch_data.Dataset):\n",
    "    def __init__(self, paths):\n",
    "        self.paths = paths\n",
    "          \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        _id = self.paths[index]\n",
    "        patient_path = base_path + f\"/train/{str(_id).zfill(5)}/\"\n",
    "        channels = []\n",
    "        for t in (IMAGE_TYPE, IMAGE_TYPE, IMAGE_TYPE): # \"T2w\"\n",
    "            t_paths = sorted(\n",
    "                glob.glob(os.path.join(patient_path, t, \"*\")), \n",
    "                key=lambda x: int(x[:-4].split(\"-\")[-1]),\n",
    "            )\n",
    "            # start, end = int(len(t_paths) * 0.475), int(len(t_paths) * 0.525)\n",
    "            x = len(t_paths)\n",
    "            if x < IMAGE_SAMP_DIV:\n",
    "                r = range(x)\n",
    "            else:\n",
    "                d = x // IMAGE_SAMP_DIV\n",
    "                r = range(d, x - d, d)\n",
    "                \n",
    "            channel = []\n",
    "            # for i in range(start, end + 1):\n",
    "            for i in r:\n",
    "                channel.append(cv2.resize(load_dicom(t_paths[i]), IMAGE_SIZE) / 255)\n",
    "            channel = np.mean(channel, axis=0)\n",
    "            channels.append(channel)\n",
    "        \n",
    "        return {\"X\": torch.tensor(channels).float(), \"id\": _id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a06612fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission = pd.read_csv(base_path + \"/sample_submission.csv\")\n",
    "submission = pd.read_csv(base_path + \"/test_df.csv\")\n",
    "\n",
    "test_data_retriever = DataRetriever(\n",
    "    submission[\"BraTS21ID\"].values, \n",
    ")\n",
    "\n",
    "test_loader = torch_data.DataLoader(\n",
    "    test_data_retriever,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24aad9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(result, threshold=0.5):\n",
    "\n",
    "    confusion_matrix = [[0, 0], [0, 0]]\n",
    "\n",
    "#     for i in range(len(result3)):\n",
    "#         threshold = 1 if result3.loc[i, \"MGMT_value_x\"] > threshold else 0\n",
    "#         confusion_matrix[result3.loc[i, \"MGMT_value_y\"]][threshold] += 1\n",
    "        \n",
    "    for idx, data in result.iterrows():\n",
    "        res = 1 if data.MGMT_value_x > threshold else 0\n",
    "        confusion_matrix[int(data.MGMT_value_y)][res] += 1\n",
    "\n",
    "    return confusion_matrix\n",
    "\n",
    "def get_acc_recall(arr):\n",
    "    acc = sum((arr[0][0], arr[1][1]))/sum((sum(arr[0]), sum(arr[1])))\n",
    "    recall = arr[1][1] / sum(arr[1])\n",
    "    print(f\"Acc: {acc} \\t Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5548c0f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y_pred = []\n",
    "ids = []\n",
    "\n",
    "for e, batch in enumerate(test_loader):\n",
    "    print(f\"{e}/{len(test_loader)}\", end=\"\\r\")\n",
    "    with torch.no_grad():\n",
    "        tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n",
    "        for model in models:\n",
    "            tmp_res = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n",
    "            tmp_pred += tmp_res\n",
    "        y_pred.extend(tmp_pred)\n",
    "        ids.extend(batch[\"id\"].numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd6f8355",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value_x\": y_pred, 'MGMT_value_y':submission['MGMT_value']})\n",
    "# submission.to_csv(\"submission_efficientnet_b2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3d72624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23b8fbeb640>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.hist(submission[\"MGMT_value_x\"])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d3eb3b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BraTS21ID</th>\n",
       "      <th>MGMT_value_x</th>\n",
       "      <th>MGMT_value_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>0.490943</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>753</td>\n",
       "      <td>0.518397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303</td>\n",
       "      <td>0.479873</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106</td>\n",
       "      <td>0.442441</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>171</td>\n",
       "      <td>0.468423</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>703</td>\n",
       "      <td>0.510690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>21</td>\n",
       "      <td>0.513315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>444</td>\n",
       "      <td>0.484937</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>95</td>\n",
       "      <td>0.525983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>640</td>\n",
       "      <td>0.522639</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BraTS21ID  MGMT_value_x  MGMT_value_y\n",
       "0          107      0.490943             1\n",
       "1          753      0.518397             0\n",
       "2          303      0.479873             1\n",
       "3          106      0.442441             1\n",
       "4          171      0.468423             1\n",
       "..         ...           ...           ...\n",
       "112        703      0.510690             0\n",
       "113         21      0.513315             0\n",
       "114        444      0.484937             0\n",
       "115         95      0.525983             0\n",
       "116        640      0.522639             1\n",
       "\n",
       "[117 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b602b15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21, 35], [28, 33]]\n",
      "Acc: 0.46153846153846156 \t Recall: 0.5409836065573771\n"
     ]
    }
   ],
   "source": [
    "confMatrix = get_confusion_matrix(submission)\n",
    "print(confMatrix)\n",
    "\n",
    "rec = get_acc_recall(confMatrix)\n",
    "\n",
    "\n",
    "# print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969886f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "posecnn",
   "language": "python",
   "name": "posecnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
