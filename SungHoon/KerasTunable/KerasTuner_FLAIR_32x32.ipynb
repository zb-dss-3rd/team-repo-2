{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13879202966622157460\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 2249929524\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5588758835528376883\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRI_Type = 'FLAIR'\n",
    "Img_Size = 32 # 정사각형 한 변의 픽셀값 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # 환경변수 설정 구문은 일단 생략\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import pydicom # Handle MRI images\n",
    "\n",
    "import cv2  # OpenCV - https://docs.opencv.org/master/d6/d00/tutorial_py_root.html\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import model_selection\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.initializers import RandomUniform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BraTS21ID</th>\n",
       "      <th>MGMT_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>1007</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>1008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>1009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>582 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BraTS21ID  MGMT_value\n",
       "0            0           1\n",
       "1            2           1\n",
       "2            3           0\n",
       "3            5           1\n",
       "4            6           1\n",
       "..         ...         ...\n",
       "577       1005           1\n",
       "578       1007           1\n",
       "579       1008           1\n",
       "580       1009           0\n",
       "581       1010           0\n",
       "\n",
       "[582 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_dir = Path('./')\n",
    "\n",
    "mri_types = [\"FLAIR\", \"T1w\", \"T2w\", \"T1wCE\"]\n",
    "excluded_images = [109, 123, 709] # Bad images\n",
    "\n",
    "train_df = pd.read_csv(\"./train_labels.csv\")\n",
    "test_df = pd.read_csv(\"./sample_submission.csv\")\n",
    "sample_submission = pd.read_csv(\"./sample_submission.csv\")\n",
    "\n",
    "train_df = train_df[~train_df.BraTS21ID.isin(excluded_images)].reset_index(drop=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom(path, size = 224):\n",
    "    ''' \n",
    "    Reads a DICOM image, standardizes so that the pixel values are between 0 and 1, then rescales to 0 and 255\n",
    "    \n",
    "    Not super sure if this kind of scaling is appropriate, but everyone seems to do it. \n",
    "    '''\n",
    "    dicom = pydicom.read_file(path)\n",
    "    data = dicom.pixel_array\n",
    "    # transform data into black and white scale / grayscale\n",
    "#     data = data - np.min(data)\n",
    "    if np.max(data) != 0:\n",
    "        data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return cv2.resize(data, (size, size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_image_paths(brats21id, image_type, folder='train'): \n",
    "    '''\n",
    "    Returns an arry of all the images of a particular type for a particular patient ID\n",
    "    '''\n",
    "    assert(image_type in mri_types)\n",
    "    \n",
    "    patient_path = os.path.join(\n",
    "        \"./%s/\" % folder, \n",
    "        str(brats21id).zfill(5),\n",
    "    )\n",
    "\n",
    "    paths = sorted(\n",
    "        glob.glob(os.path.join(patient_path, image_type, \"*\")), \n",
    "        key=lambda x: int(x[:-4].split(\"-\")[-1]),\n",
    "    )\n",
    "    \n",
    "    num_images = len(paths)\n",
    "    \n",
    "    start = int(num_images * 0.25)\n",
    "    end = int(num_images * 0.75)\n",
    "\n",
    "    interval = 3\n",
    "    \n",
    "    if num_images < 10: \n",
    "        interval = 1\n",
    "    \n",
    "    return np.array(paths[start:end:interval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_images(brats21id, image_type, folder='train', size=225):\n",
    "    return [load_dicom(path, size) for path in get_all_image_paths(brats21id, image_type, folder)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data_for_train(image_type, image_size=32):\n",
    "    global train_df\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    train_ids = []\n",
    "\n",
    "    for i in tqdm(train_df.index):\n",
    "        x = train_df.loc[i]\n",
    "        images = get_all_images(int(x['BraTS21ID']), image_type, 'train', image_size)\n",
    "        label = x['MGMT_value']\n",
    "\n",
    "        X += images\n",
    "        y += [label] * len(images)\n",
    "        train_ids += [int(x['BraTS21ID'])] * len(images)\n",
    "        assert(len(X) == len(y))\n",
    "    return np.array(X), np.array(y), np.array(train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_data_for_test(image_type, image_size=32):\n",
    "    global test_df\n",
    "    \n",
    "    X = []\n",
    "    test_ids = []\n",
    "\n",
    "    for i in tqdm(test_df.index):\n",
    "        x = test_df.loc[i]\n",
    "        images = get_all_images(int(x['BraTS21ID']), image_type, 'test', image_size)\n",
    "        X += images\n",
    "        test_ids += [int(x['BraTS21ID'])] * len(images)\n",
    "\n",
    "    return np.array(X), np.array(test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X - contains all the images for each patient \n",
    "\n",
    "trainidt - trainidt is a mask vector into X, y for training.  There's a patient id/BraTS21ID corresponding to each image (e.g. (0, 0, 0, 0, 2,2, 3,3,3,3,3,...) )\n",
    "\n",
    "testidt - testidt is a mask vector into X_test for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014987468719482422,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 582,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03dd02f1f1749cfb3b7eda8f0e9b89f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/582 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y, trainidt = get_all_data_for_train('FLAIR', image_size=Img_Size)\n",
    "# X_test, testidt = get_all_data_for_test('T1wCE', image_size=32) # 어차피 안 쓸 테스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12463, 32, 32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape # 32 * 32 이미지 16196장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12463,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:10] # 각 이미지의 라벨값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12463,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainidt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainidt[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44, 44, 44, 44, 44, 44, 44, 44, 44, 44])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainidt[1000:1010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 방식으로 split 필요\n",
    "\n",
    "# X_train, X_valid, y_train, y_valid, trainidt_train, trainidt_valid = train_test_split(X, y, trainidt, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BraTS21ID</th>\n",
       "      <th>MGMT_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>816</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>356</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>834</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BraTS21ID  MGMT_value\n",
       "0          185           1\n",
       "1          816           1\n",
       "2          707           1\n",
       "3          683           0\n",
       "4            6           1\n",
       "..         ...         ...\n",
       "463        356           0\n",
       "464         89           1\n",
       "465        217           0\n",
       "466        834           0\n",
       "467        708           1\n",
       "\n",
       "[468 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./train_df.csv')\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BraTS21ID</th>\n",
       "      <th>MGMT_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>107</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>753</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>303</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>703</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BraTS21ID  MGMT_value\n",
       "0          107           1\n",
       "1          753           0\n",
       "2          303           1\n",
       "3          106           1\n",
       "4          171           1\n",
       "..         ...         ...\n",
       "112        703           0\n",
       "113         21           0\n",
       "114        444           0\n",
       "115         95           0\n",
       "116        640           1\n",
       "\n",
       "[117 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('./test_df.csv')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "585"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(train_df['BraTS21ID']) + list(test_df['BraTS21ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "585"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list(train_df['BraTS21ID']) + list(test_df['BraTS21ID']))) # 잘 나뉘어진 것으로 확인 완료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12463"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = list(train_df['BraTS21ID'])\n",
    "test_ids = list(test_df['BraTS21ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(468, 117)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ids), len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.027921676635742188,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 29,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 12463,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c3ce3388674ed193257f8c0251d724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12463 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X_train, X_valid, y_train, y_valid, trainidt_train, trainidt_valid \n",
    "\n",
    "X_train, X_valid, y_train, y_valid, trainidt_train, trainidt_valid  = [], [], [], [], [], []\n",
    "\n",
    "for i in tqdm(range(len(X))):\n",
    "    if trainidt[i] in train_ids:\n",
    "        X_train.append(X[i])\n",
    "        y_train.append(y[i])\n",
    "        trainidt_train.append(trainidt[i])\n",
    "    else:\n",
    "        X_valid.append(X[i])\n",
    "        y_valid.append(y[i])\n",
    "        trainidt_valid.append(trainidt[i])\n",
    "        \n",
    "X_train = np.array(X_train, dtype='uint8')\n",
    "X_valid = np.array(X_valid, dtype='uint8')\n",
    "y_train = np.array(y_train, dtype='int64')\n",
    "y_valid = np.array(y_valid, dtype='int64')\n",
    "trainidt_train = np.array(trainidt_train)\n",
    "trainidt_valid = np.array(trainidt_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10011, 32, 32), (2452, 32, 32), (10011,), (2452,), (10011,), (2452,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape, trainidt_train.shape, trainidt_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0, ..., 1010, 1010, 1010])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainidt_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   3,    3,    3, ..., 1009, 1009, 1009])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainidt_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10011, 32, 32, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = tf.expand_dims(X_train, axis=-1)\n",
    "X_valid = tf.expand_dims(X_valid, axis=-1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_valid = to_categorical(y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunable Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the SIREN activation layer. Refer to https://vsitzmann.github.io/siren/ for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineDenseLayer(keras.layers.Layer):\n",
    "    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n",
    "    \n",
    "    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n",
    "    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n",
    "    # hyperparameter.\n",
    "    \n",
    "    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n",
    "    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
    "    \n",
    "    def __init__(self, features,\n",
    "                 is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.features = features\n",
    "        \n",
    "        if self.is_first:\n",
    "            initializer = RandomUniform(-1 / self.features, 1 / self.features)   \n",
    "            self.linear = keras.layers.Dense(features, kernel_initializer=initializer)\n",
    "    \n",
    "        else:\n",
    "            initializer = RandomUniform(-np.sqrt(6 / self.features) / self.omega_0, np.sqrt(6 / self.features) / self.omega_0)\n",
    "            self.linear = keras.layers.Dense(features, kernel_initializer=initializer)\n",
    "     \n",
    "\n",
    "    def call(self, input):\n",
    "        return tf.math.sin(self.omega_0 * self.linear(input))\n",
    "    \n",
    "#     def forward_with_intermediate(self, input): \n",
    "#         # For visualization of activation distributions\n",
    "#         intermediate = self.omega_0 * self.linear(input)\n",
    "#         return tf.math.sin(intermediate), intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SineConvLayer(keras.layers.Layer):\n",
    "    # See paper sec. 3.2, final paragraph, and supplement Sec. 1.5 for discussion of omega_0.\n",
    "    \n",
    "    # If is_first=True, omega_0 is a frequency factor which simply multiplies the activations before the \n",
    "    # nonlinearity. Different signals may require different omega_0 in the first layer - this is a \n",
    "    # hyperparameter.\n",
    "    \n",
    "    # If is_first=False, then the weights will be divided by omega_0 so as to keep the magnitude of \n",
    "    # activations constant, but boost gradients to the weight matrix (see supplement Sec. 1.5)\n",
    "    \n",
    "    def __init__(self, features, kernel_size,\n",
    "                 is_first=False, omega_0=30):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.features = features\n",
    "        \n",
    "        if self.is_first:\n",
    "            initializer = RandomUniform(-1 / self.features, 1 / self.features)            \n",
    "            self.conv = keras.layers.Conv2D(features, kernel_size, kernel_initializer=initializer)\n",
    "            \n",
    "        else:\n",
    "            initializer = RandomUniform(-np.sqrt(6 / self.features) / self.omega_0, np.sqrt(6 / self.features) / self.omega_0)\n",
    "            self.conv = keras.layers.Conv2D(features, kernel_size, kernel_initializer=initializer)\n",
    "            \n",
    "\n",
    "    def call(self, input):\n",
    "        return tf.math.sin(self.omega_0 * self.conv(input))\n",
    "    \n",
    "#     def forward_with_intermediate(self, input): \n",
    "#         # For visualization of activation distributions\n",
    "#         intermediate = self.omega_0 * self.linear(input)\n",
    "#         return tf.math.sin(intermediate), intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(hp):\n",
    "    inputs = keras.Input(shape=X_train.shape[1:])\n",
    "    \n",
    "    x = keras.layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs)\n",
    "\n",
    "#     num_block = hp.Int('num_block', min_value=2, max_value=5, step=1)\n",
    "#     num_filters = hp.Int('num_filters', min_value=32, max_value=128, step=32)\n",
    "    \n",
    "#     x = keras.layers.Conv2D(64, kernel_size=(4, 4), activation=\"relu\", name=\"Conv_1\")(x)\n",
    "    x = keras.layers.Conv2D(filters=hp.Int('units_Conv_1_' + str(0),\n",
    "                                            min_value=64,\n",
    "                                            max_value=256,\n",
    "                                            step=32),\n",
    "                            kernel_size=(4, 4),\n",
    "                            activation=\"relu\", \n",
    "                            name=\"Conv_1\")(x)\n",
    "\n",
    "    x = keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "#     x = keras.layers.Conv2D(32, kernel_size=(2, 2), activation=\"relu\", name=\"Conv_2\")(x)\n",
    "    x = keras.layers.Conv2D(filters=hp.Int('units_conv2_' + str(1),\n",
    "                                            min_value=16,\n",
    "                                            max_value=128,\n",
    "                                            step=16),\n",
    "                            kernel_size=(2, 2),\n",
    "                            activation=\"relu\",\n",
    "                            name=\"Conv_2\")(x)\n",
    "\n",
    "    x = keras.layers.MaxPool2D(pool_size=(1, 1))(x)\n",
    "    \n",
    "#     for i in range(num_block):\n",
    "#         x = keras.layers.Conv2D(num_filters, \n",
    "#                                 kernel_size=(4, 4),\n",
    "#                                 activation=\"relu\",\n",
    "#                                 )(x)\n",
    "    \n",
    "#         x = keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "#     x = keras.layers.Conv2D(32, kernel_size=(2, 2), activation=\"relu\", name=\"Conv_2\")(x)\n",
    "#     x = keras.layers.MaxPool2D(pool_size=(1, 1))(x)\n",
    "\n",
    "#     h = keras.layers.Dropout(0.1)(h)\n",
    "    x = layers.Dropout(\n",
    "        hp.Float('dense_dropout', min_value=0., max_value=0.7)\n",
    "    )(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "#     reduction_type = hp.Choice('reduction_type', ['flatten', 'avg'])\n",
    "#     if reduction_type == 'flatten':\n",
    "#         x = layers.Flatten()(x)\n",
    "#     else:\n",
    "#         x = layers.GlobalAveragePooling2D()(x)\n",
    "        \n",
    "#     x = keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "    x = layers.Dense(\n",
    "        units=hp.Int('num_dense_units', min_value=16, max_value=64, step=8),\n",
    "        activation='relu'\n",
    "    )(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    roc_auc = tf.keras.metrics.AUC(name='roc_auc', curve='ROC')\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[roc_auc]\n",
    "    )\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://www.tensorflow.org/guide/keras/preprocessing_layers\n",
    "- https://keras.io/examples/vision/image_classification_from_scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model_augmented(hp):\n",
    "    input_shape = (Img_Size, Img_Size, 1)\n",
    "    classes = 10\n",
    "\n",
    "    # Create a data augmentation stage with horizontal flipping, rotations, zooms\n",
    "#     data_augmentation = keras.Sequential(\n",
    "#         [\n",
    "#             layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "#             layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "#             layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "#         ]\n",
    "#     )\n",
    "    \n",
    "    data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "    shape=X_train.shape[1:]\n",
    "    print(f\"shape={shape}\") # shape=(32, 32, 1)\n",
    "    \n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = data_augmentation(inputs)\n",
    "\n",
    "    x = keras.layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n",
    "#     x = layers.experimental.preprocessing.RandomFlip(\"horizontal\")(x),\n",
    "#     x = layers.experimental.preprocessing.RandomRotation(0.1)(x),\n",
    "#     x = layers.experimental.preprocessing.RandomZoom(\n",
    "#         height_factor = 0.2,\n",
    "#         width_factor = -0.3,\n",
    "#         fill_mode = \"constant\",\n",
    "#         interpolation = \"bilinear\",\n",
    "#         seed = 42\n",
    "#     )(x),\n",
    "#     num_block = hp.Int('num_block', min_value=2, max_value=5, step=1)\n",
    "#     num_filters = hp.Int('num_filters', min_value=32, max_value=128, step=32)\n",
    "    \n",
    "#     x = keras.layers.Conv2D(64, kernel_size=(4, 4), activation=\"relu\", name=\"Conv_1\")(x)\n",
    "    x = keras.layers.Conv2D(filters=hp.Int('units_Conv_1_' + str(0),\n",
    "                                            min_value=64,\n",
    "                                            max_value=256,\n",
    "                                            step=32),\n",
    "                            kernel_size=(4, 4),\n",
    "                            activation=\"relu\", \n",
    "                            name=\"Conv_1\")(x)\n",
    "\n",
    "    x = keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "#     x = keras.layers.Conv2D(32, kernel_size=(2, 2), activation=\"relu\", name=\"Conv_2\")(x)\n",
    "    x = keras.layers.Conv2D(filters=hp.Int('units_conv2_' + str(1),\n",
    "                                            min_value=16,\n",
    "                                            max_value=128,\n",
    "                                            step=16),\n",
    "                            kernel_size=(2, 2),\n",
    "                            activation=\"relu\",\n",
    "                            name=\"Conv_2\")(x)\n",
    "\n",
    "    x = keras.layers.MaxPool2D(pool_size=(1, 1))(x)\n",
    "    \n",
    "#     for i in range(num_block):\n",
    "#         x = keras.layers.Conv2D(num_filters, \n",
    "#                                 kernel_size=(4, 4),\n",
    "#                                 activation=\"relu\",\n",
    "#                                 )(x)\n",
    "    \n",
    "#         x = keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "#     x = keras.layers.Conv2D(32, kernel_size=(2, 2), activation=\"relu\", name=\"Conv_2\")(x)\n",
    "#     x = keras.layers.MaxPool2D(pool_size=(1, 1))(x)\n",
    "\n",
    "#     h = keras.layers.Dropout(0.1)(h)\n",
    "    x = layers.Dropout(\n",
    "        hp.Float('dense_dropout', min_value=0., max_value=0.7)\n",
    "    )(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "#     reduction_type = hp.Choice('reduction_type', ['flatten', 'avg'])\n",
    "#     if reduction_type == 'flatten':\n",
    "#         x = layers.Flatten()(x)\n",
    "#     else:\n",
    "#         x = layers.GlobalAveragePooling2D()(x)\n",
    "        \n",
    "#     x = keras.layers.Dense(32, activation=\"relu\")(x)\n",
    "    x = layers.Dense(\n",
    "        units=hp.Int('num_dense_units', min_value=16, max_value=64, step=8),\n",
    "        activation='relu'\n",
    "    )(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    roc_auc = tf.keras.metrics.AUC(name='roc_auc', curve='ROC')\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[roc_auc]\n",
    "    )\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "\n",
    "def make_model_siren(hp):\n",
    "    inputs = keras.Input(shape=X_train.shape[1:])\n",
    "    \n",
    "    x = keras.layers.experimental.preprocessing.Rescaling(1.0 / 255)(inputs)\n",
    "\n",
    "    x = SineConvLayer(features=hp.Int('features_conv_1', min_value=64, max_value=256, step=32),\n",
    "                      kernel_size=hp.Int('kernel_conv_1', min_value=2, max_value=7, step=1),\n",
    "                      is_first=True, \n",
    "                      omega_0=hp.Int('omega_0_conv_1', min_value=10, max_value=50, step=5))(x)\n",
    "    \n",
    "    x = keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = SineConvLayer(features=hp.Int('features_conv_2', min_value=16, max_value=128, step=16),\n",
    "                      kernel_size=hp.Int('kernel_conv_2', min_value=2, max_value=7, step=1),\n",
    "                      is_first=False, \n",
    "                      omega_0=hp.Int('omega_0_conv_2', min_value=10, max_value=50, step=5))(x)\n",
    "\n",
    "    x = keras.layers.MaxPool2D(pool_size=(1, 1))(x)\n",
    "    \n",
    "    x = layers.Dropout(\n",
    "        hp.Float('dense_dropout', min_value=0., max_value=0.7)\n",
    "    )(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = SineDenseLayer(features=hp.Int('features_dense_1', min_value=64, max_value=256, step=32),\n",
    "                      is_first=False, \n",
    "                      omega_0=hp.Int('omega_0_dense_1', min_value=10, max_value=50, step=5))(x)\n",
    "\n",
    "    outputs = keras.layers.Dense(2, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    roc_auc = tf.keras.metrics.AUC(name='roc_auc', curve='ROC')\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[roc_auc]\n",
    "    )\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 05m 49s]\n",
      "val_loss: 0.6762886047363281\n",
      "\n",
      "Best val_loss So Far: 0.673584520816803\n",
      "Total elapsed time: 00h 28m 34s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.tuners.BayesianOptimization(\n",
    "#     make_model_siren,\n",
    "#     make_model,\n",
    "    make_model_augmented,\n",
    "    objective='val_loss',\n",
    "    max_trials=5,  # Set to 5 to run quicker, but need 100+ for good results\n",
    "    overwrite=True)\n",
    "\n",
    "callbacks=[keras.callbacks.EarlyStopping(monitor='val_roc_acc', mode='max', patience=3, baseline=0.9)]\n",
    "\n",
    "tuner.search(X_train, y_train, validation_split=0.2, callbacks=callbacks, verbose=1, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the best epoch value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 32, 32, 1)]       0         \n",
      "                                                                 \n",
      " rescaling_1 (Rescaling)     (None, 32, 32, 1)         0         \n",
      "                                                                 \n",
      " Conv_1 (Conv2D)             (None, 29, 29, 256)       4352      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 14, 14, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " Conv_2 (Conv2D)             (None, 13, 13, 16)        16400     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 13, 13, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 13, 13, 16)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2704)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                173120    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 194,002\n",
      "Trainable params: 194,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "best_model = make_model(best_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: KerasTuner_best_model_FLAIR\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: KerasTuner_best_model_FLAIR\\assets\n"
     ]
    }
   ],
   "source": [
    "best_model.save(\"KerasTuner_best_model_FLAIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "251/251 [==============================] - 5s 16ms/step - loss: 0.6485 - roc_auc: 0.6729 - val_loss: 0.7020 - val_roc_auc: 0.6086\n",
      "Epoch 2/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.6352 - roc_auc: 0.6932 - val_loss: 0.7214 - val_roc_auc: 0.5949\n",
      "Epoch 3/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.6218 - roc_auc: 0.7137 - val_loss: 0.7421 - val_roc_auc: 0.5885\n",
      "Epoch 4/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.6157 - roc_auc: 0.7205 - val_loss: 0.6844 - val_roc_auc: 0.6091\n",
      "Epoch 5/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.6036 - roc_auc: 0.7364 - val_loss: 0.7131 - val_roc_auc: 0.6122\n",
      "Epoch 6/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.5918 - roc_auc: 0.7484 - val_loss: 0.7176 - val_roc_auc: 0.6106\n",
      "Epoch 7/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.5771 - roc_auc: 0.7656 - val_loss: 0.6995 - val_roc_auc: 0.6175\n",
      "Epoch 8/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.5594 - roc_auc: 0.7811 - val_loss: 0.7121 - val_roc_auc: 0.6210\n",
      "Epoch 9/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.5458 - roc_auc: 0.7950 - val_loss: 0.7018 - val_roc_auc: 0.6286\n",
      "Epoch 10/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.5211 - roc_auc: 0.8159 - val_loss: 0.7065 - val_roc_auc: 0.6239\n",
      "Epoch 11/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.5061 - roc_auc: 0.8285 - val_loss: 0.7268 - val_roc_auc: 0.6234\n",
      "Epoch 12/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 0.4936 - roc_auc: 0.8400 - val_loss: 0.7492 - val_roc_auc: 0.6207\n",
      "Epoch 13/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.4821 - roc_auc: 0.8470 - val_loss: 0.7475 - val_roc_auc: 0.5913\n",
      "Epoch 14/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 0.4737 - roc_auc: 0.8540 - val_loss: 0.7363 - val_roc_auc: 0.5879\n",
      "Epoch 15/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.4577 - roc_auc: 0.8627 - val_loss: 0.7729 - val_roc_auc: 0.5724\n",
      "Epoch 16/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.4432 - roc_auc: 0.8730 - val_loss: 0.7421 - val_roc_auc: 0.6017\n",
      "Epoch 17/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 0.4262 - roc_auc: 0.8837 - val_loss: 0.8084 - val_roc_auc: 0.5871\n",
      "Epoch 18/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.4136 - roc_auc: 0.8919 - val_loss: 0.8225 - val_roc_auc: 0.5918\n",
      "Epoch 19/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 0.4056 - roc_auc: 0.8955 - val_loss: 0.8426 - val_roc_auc: 0.5869\n",
      "Epoch 20/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.3908 - roc_auc: 0.9026 - val_loss: 0.8278 - val_roc_auc: 0.5835\n",
      "Epoch 21/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.3881 - roc_auc: 0.9053 - val_loss: 0.8292 - val_roc_auc: 0.5855\n",
      "Epoch 22/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.3770 - roc_auc: 0.9110 - val_loss: 0.8555 - val_roc_auc: 0.5752\n",
      "Epoch 23/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 0.3732 - roc_auc: 0.9121 - val_loss: 0.8515 - val_roc_auc: 0.6078\n",
      "Epoch 24/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.3617 - roc_auc: 0.9191 - val_loss: 0.8372 - val_roc_auc: 0.5897\n",
      "Epoch 25/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.3400 - roc_auc: 0.9286 - val_loss: 0.9229 - val_roc_auc: 0.5847\n",
      "Epoch 26/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.3440 - roc_auc: 0.9269 - val_loss: 0.8653 - val_roc_auc: 0.5925\n",
      "Epoch 27/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.3364 - roc_auc: 0.9296 - val_loss: 0.9055 - val_roc_auc: 0.5889\n",
      "Epoch 28/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.3279 - roc_auc: 0.9333 - val_loss: 0.8806 - val_roc_auc: 0.5849\n",
      "Epoch 29/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.3156 - roc_auc: 0.9385 - val_loss: 0.9360 - val_roc_auc: 0.5850\n",
      "Epoch 30/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.3154 - roc_auc: 0.9388 - val_loss: 0.9224 - val_roc_auc: 0.5772\n",
      "Epoch 31/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 0.3014 - roc_auc: 0.9443 - val_loss: 0.9885 - val_roc_auc: 0.5816\n",
      "Epoch 32/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.2949 - roc_auc: 0.9465 - val_loss: 0.9697 - val_roc_auc: 0.5665\n",
      "Epoch 33/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.3028 - roc_auc: 0.9438 - val_loss: 0.9298 - val_roc_auc: 0.5841\n",
      "Epoch 34/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.2985 - roc_auc: 0.9450 - val_loss: 0.9292 - val_roc_auc: 0.5855\n",
      "Epoch 35/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 0.2863 - roc_auc: 0.9502 - val_loss: 0.9804 - val_roc_auc: 0.5987\n",
      "Epoch 36/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.2837 - roc_auc: 0.9504 - val_loss: 0.9721 - val_roc_auc: 0.5777\n",
      "Epoch 37/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 0.2711 - roc_auc: 0.9553 - val_loss: 1.0054 - val_roc_auc: 0.5574\n",
      "Epoch 38/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 0.2669 - roc_auc: 0.9565 - val_loss: 1.0186 - val_roc_auc: 0.5759\n",
      "Epoch 39/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 0.2722 - roc_auc: 0.9551 - val_loss: 0.9885 - val_roc_auc: 0.5783\n",
      "Epoch 40/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 0.2629 - roc_auc: 0.9578 - val_loss: 0.9887 - val_roc_auc: 0.5860\n",
      "Epoch 41/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.2559 - roc_auc: 0.9598 - val_loss: 1.0200 - val_roc_auc: 0.5958\n",
      "Epoch 42/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 0.2583 - roc_auc: 0.9595 - val_loss: 1.0174 - val_roc_auc: 0.5744\n",
      "Epoch 43/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 0.2535 - roc_auc: 0.9608 - val_loss: 1.0573 - val_roc_auc: 0.5591\n",
      "Epoch 44/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.2434 - roc_auc: 0.9640 - val_loss: 1.0826 - val_roc_auc: 0.5852\n",
      "Epoch 45/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.2412 - roc_auc: 0.9644 - val_loss: 1.0441 - val_roc_auc: 0.5814\n",
      "Epoch 46/50\n",
      "251/251 [==============================] - 4s 17ms/step - loss: 0.2536 - roc_auc: 0.9607 - val_loss: 1.0551 - val_roc_auc: 0.5480\n",
      "Epoch 47/50\n",
      "251/251 [==============================] - 4s 16ms/step - loss: 0.2498 - roc_auc: 0.9618 - val_loss: 1.0891 - val_roc_auc: 0.5658\n",
      "Epoch 48/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.2344 - roc_auc: 0.9665 - val_loss: 1.0897 - val_roc_auc: 0.5763\n",
      "Epoch 49/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.2448 - roc_auc: 0.9633 - val_loss: 1.0364 - val_roc_auc: 0.5864\n",
      "Epoch 50/50\n",
      "251/251 [==============================] - 4s 15ms/step - loss: 0.2323 - roc_auc: 0.9670 - val_loss: 1.0046 - val_roc_auc: 0.5863\n"
     ]
    }
   ],
   "source": [
    "history = best_model.fit(X_train, y_train, validation_split=0.2, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77/77 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BraTS21ID</th>\n",
       "      <th>MGMT_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>0.418605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>0.651163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>0.681818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>823</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>837</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1007</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1008</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1009</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BraTS21ID  MGMT_value\n",
       "0            3    0.500000\n",
       "1            9    0.400000\n",
       "2           21    0.418605\n",
       "3           22    0.651163\n",
       "4           25    0.681818\n",
       "..         ...         ...\n",
       "111        823    0.000000\n",
       "112        837    0.300000\n",
       "113       1007    0.095238\n",
       "114       1008    0.600000\n",
       "115       1009    0.750000\n",
       "\n",
       "[116 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_valid)\n",
    "\n",
    "pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "result = pd.DataFrame(trainidt_valid)\n",
    "result[1] = pred\n",
    "\n",
    "result.columns = [\"BraTS21ID\", \"MGMT_value\"]\n",
    "result2 = result.groupby(\"BraTS21ID\", as_index=False).mean()\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BraTS21ID</th>\n",
       "      <th>MGMT_value_x</th>\n",
       "      <th>MGMT_value_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>0.418605</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>837</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1007</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1008</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1009</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BraTS21ID  MGMT_value_x  MGMT_value_y\n",
       "0            3      0.500000             0\n",
       "1            9      0.400000             0\n",
       "2           21      0.418605             0\n",
       "3           22      0.651163             0\n",
       "4           25      0.681818             1\n",
       "..         ...           ...           ...\n",
       "111        823      0.000000             1\n",
       "112        837      0.300000             0\n",
       "113       1007      0.095238             1\n",
       "114       1008      0.600000             1\n",
       "115       1009      0.750000             0\n",
       "\n",
       "[116 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = result2.merge(test_df, on=\"BraTS21ID\")\n",
    "result2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC=0.46979166666666666\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(\n",
    "    result2.MGMT_value_y,\n",
    "    result2.MGMT_value_x,\n",
    ")\n",
    "print(f\"Validation AUC={auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# result3 = result2[:]\n",
    "# result3[\"0.5 Pred\"] = round(result3[\"MGMT_value_x\"])\n",
    "# result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result3['0.5 Pred'] = result3['0.5 Pred'].astype('int64')\n",
    "# result3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result3.loc[2, \"MGMT_value_y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix05 = [[0, 0], [0, 0]]\n",
    "\n",
    "# for i in range(len(result3)):\n",
    "#     confusion_matrix05[result3.loc[i, \"MGMT_value_y\"]][result3.loc[i, \"0.5 Pred\"]] += 1\n",
    "        \n",
    "# confusion_matrix05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confusion_matrix(threshold=0.5):\n",
    "\n",
    "    confusion_matrix = [[0, 0], [0, 0]]\n",
    "\n",
    "    for i in range(len(result2)):\n",
    "        tmp = 1 if result2.loc[i, \"MGMT_value_x\"] > threshold else 0\n",
    "        confusion_matrix[result2.loc[i, \"MGMT_value_y\"]][tmp] += 1\n",
    "\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc_recall(arr):\n",
    "    acc = sum((arr[0][0], arr[1][1]))/sum((sum(arr[0]), sum(arr[1])))\n",
    "    recall = arr[1][1] / sum(arr[1])\n",
    "    print(f\"Acc: {acc} \\t Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[28, 28], [30, 30]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result05 = get_confusion_matrix(threshold=0.5)\n",
    "result05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.5 \t Recall: 0.5\n"
     ]
    }
   ],
   "source": [
    "get_acc_recall(result05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[19, 37], [21, 39]]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result06 = get_confusion_matrix(threshold=0.3)\n",
    "result06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.5 \t Recall: 0.65\n"
     ]
    }
   ],
   "source": [
    "get_acc_recall(result06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KerasTunable_FLAIR_32x32.csv'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"KerasTunable_\" + MRI_Type + \"_\" + str(Img_Size) + \"x\" + str(Img_Size) + \".csv\"\n",
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2.to_csv(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2663a481603455b1fe2a66f2bce99018ef66a408212d460f91117e7590fddab4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
